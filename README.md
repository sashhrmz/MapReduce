# MapReduce

## Web Robot

### Task

Определить, на какие страницы можно попасть из стартовых при установленном ограничении глубины захода.
Считаем, что робот переходит только по ссылкам из *html <a href= >* . Нельзя дважды посещать одну вершину графа обхода.

**Входные данные**

Файл с *url* формата: *url \t ""*
Числовой параметр: Глубина захода.

**Выходные данные**

Список страниц, до которых добрался робот, по одной странице в строке.

### Solution

**Map**

*Script map.py*. Он берёт *html* код из сайта с пришедшими ему *url*. На входе множество пар
вида *\url\t0*. На выходе множество пар включая пришедшие на вход. Пришедшие на вход
пары будет записаны с ключом 1, все остальные с ключом 0.

**Reduce**

*Script reduce*. На вход подаётся файл с одинаковыми ключами. Reduce удаляет дубликаты.
Если на вход с данным ключом есть значение 1, то на выходе будет пара *\url\t1*. Если же
на входе все строки имеют вид *\url\t0*, то на выходе будет *\url\t0*.

**Sort**

*Script sort*. Внешняя сортировка. На входе файл с большим количеством данных, которые
нам нужно отсортировать. Мы бьём его на маленькие файлы. После из каждого файла
достаем по строке и кладём в *std::priority_queue*. При извлечении элемента из
*std::priority_queue* мы определяем из какого файла, мы его достали и берём оттуда ещё
один элемент. Действуем таким образом, пока очередь не опустеет. На выходе получаем
отсортированный файл.

**MapReduce**

*MapReduce/map*.Так как файл может быть очень большой, я делю его на множество более
мелких файлов и подаю на вход множеству *mappers*. Когда все они заканчивают свою
работу, я делаю merge для выходных файлов *mappers* (записываю всю информацию из
этих файлов в один).

*MapReduce/Reduce*. Здесь предполагается, что входной файл отсортирован. Я создаю
множество файлов, где в каждом файле - одинаковые ссылки. После подаю все эти файлы
на вход множеству reducers, жду пока они закончат и делаю *merge* всех выходных файлов
*reducers* (записываю всю информацию из этих файлов в один).

**Run**

*Script run.*

Запускается строкой *./run path_to_mapreduce path_to_map path_to_sort path_to_reduce depth
input_file*. Создается выходной файл *“result_of_work.txt”*. После *depth* раз вызывается следующая
последовательность действий :

1. Из общего выходного файла достаются все непосещенные ссылки(с ключом 0).
2. Они подаются на вход *MapReduce/map -> map_output*.
3. *map_output* подаётся на вход скрипту *sort -> sort_output*.
4. *sort_output* подаётся на вход *MapReduce/reduce -> reduce_output*.
5. После происходит *merge reduce_output* и общего выходного файла.
6. После снова нужно удалить дубликаты.
7. Общий выходной файл подаётся на вход скрипту *sort -> sort_output*.
8. *sort_output* подаётся на вход *MapReduce/reduce ->* общий выходной файл.
